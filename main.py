import os
import re
import datetime
from fastapi import FastAPI, Query, Request
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from typing import Optional
from urllib.parse import quote
import requests
import xmltodict
from bs4 import BeautifulSoup

PRIVACY_URL = "https://github.com/KD-YOON/privacy-policy"
PRIVACY_NOTICE = (
    "ë³¸ ì„œë¹„ìŠ¤ì˜ ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ì€ https://github.com/KD-YOON/privacy-policy ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
    "â€» ë™ì˜/í—ˆìš© ì•ˆë‚´ ë°˜ë³µ ë°©ì§€ëŠ” ë°˜ë“œì‹œ í”„ë¡ íŠ¸(ì›¹/ì•±/ì±—ë´‡)ì—ì„œ ë™ì˜ ì´ë ¥ ì €ì¥ ë° ì œì–´í•´ì•¼ í•©ë‹ˆë‹¤."
)

def add_privacy_notice(data):
    if isinstance(data, dict):
        data['privacy_notice'] = PRIVACY_NOTICE
        data['privacy_policy_url'] = PRIVACY_URL
    return data

API_KEY = os.environ.get("OC_KEY", "default_key")

app = FastAPI(
    title="School LawBot API",
    description="êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° DRF API + HTML í¬ë¡¤ë§ ê¸°ë°˜ ì‹¤ì‹œê°„ ì¡°ë¬¸Â·ê°€ì§€ì¡°ë¬¸Â·í•­Â·í˜¸ êµ¬ì¡°í™” ìë™í™”",
    version="9.1.0",
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json"
)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

KNOWN_LAWS = {
    "í•™êµí­ë ¥ì˜ˆë°©ë²•": "í•™êµí­ë ¥ì˜ˆë°© ë° ëŒ€ì±…ì— ê´€í•œ ë²•ë¥ ",
    "í•™êµí­ë ¥ì˜ˆë°©ë²• ì‹œí–‰ë ¹": "í•™êµí­ë ¥ì˜ˆë°© ë° ëŒ€ì±…ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ë ¹",
    "ê°œì¸ì •ë³´ë³´í˜¸ë²•": "ê°œì¸ì •ë³´ ë³´í˜¸ë²•",
}

recent_logs = []

def resolve_full_law_name(law_name: str) -> str:
    name = law_name.replace(" ", "").strip()
    for k, v in KNOWN_LAWS.items():
        if name == k.replace(" ", ""):
            return v
    return law_name

def normalize_law_name(name: str) -> str:
    return name.replace(" ", "").strip()

def normalize_article_no(article_no_raw):
    # ì…ë ¥ê°’ì—ì„œ ê³µë°± ë“± ì œê±°ë§Œ (ë§í¬ ìƒì„±ì€ fix_article_noì—ì„œ ì²˜ë¦¬)
    if not article_no_raw:
        return article_no_raw
    s = article_no_raw.replace(" ", "")
    s = re.sub(r"ì œ(\d+)ì¡°ì¡°", r"ì œ\1ì¡°", s)
    s = re.sub(r"(\d+)ì¡°ì¡°", r"\1ì¡°", s)
    return s

def fix_article_no(article_no):
    """
    '14' â†’ 'ì œ14ì¡°', '17ì˜3' â†’ 'ì œ17ì¡°ì˜3', ì´ë¯¸ í¬ë§·ì´ë©´ ê·¸ëŒ€ë¡œ
    """
    s = str(article_no).replace(" ", "")
    # ì™„ì „ì²´ëŠ” ê·¸ëŒ€ë¡œ ('ì œ14ì¡°', 'ì œ17ì¡°ì˜3' ë“±)
    if re.match(r'^ì œ\d+ì¡°(ì˜\d+)?$', s):
        return s
    # '14' â†’ 'ì œ14ì¡°'
    if s.isdigit():
        return f'ì œ{s}ì¡°'
    # '17ì˜3' â†’ 'ì œ17ì¡°ì˜3'
    m = re.match(r"^(\d+)ì˜(\d+)$", s)
    if m:
        return f"ì œ{m.group(1)}ì¡°ì˜{m.group(2)}"
    # í˜¹ì‹œ ì•ë’¤ë¡œ 'ì œ'/'ì¡°' ì—†ëŠ” ì´ìƒí•œ ê°’ì´ë©´ ë§ˆì§€ë§‰ìœ¼ë¡œ ë³´ì •
    if not s.startswith('ì œ'):
        s = 'ì œ' + s
    if not ('ì¡°' in s):
        s = s + 'ì¡°'
    return s

def parse_article_input(article_no_raw):
    if not article_no_raw:
        return None, None, None, None, False
    s = article_no_raw.replace(" ", "")
    m = re.match(r"ì œ(\d+)ì¡°ì˜(\d+)(?:ì œ(\d+)í•­)?(?:ì œ(\d+)í˜¸)?", s)
    if m:
        return int(m.group(1)), int(m.group(2)), int(m.group(3)) if m.group(3) else None, int(m.group(4)) if m.group(4) else None, True
    m = re.match(r"ì œ(\d+)ì¡°(?:ì œ(\d+)í•­)?(?:ì œ(\d+)í˜¸)?", s)
    if m:
        return int(m.group(1)), None, int(m.group(2)) if m.group(2) else None, int(m.group(3)) if m.group(3) else None, False
    return None, None, None, None, False

def make_article_link(law_name, article_no):
    law_url_name = quote(law_name.replace(" ", ""), safe='')
    if article_no:
        article_path = quote(fix_article_no(article_no), safe='')  # fix_article_noë¥¼ ê±°ì¹œë‹¤
        return f"https://www.law.go.kr/ë²•ë ¹/{law_url_name}/{article_path}"
    else:
        return f"https://www.law.go.kr/ë²•ë ¹/{law_url_name}"

def split_article_text_to_structure(text):
    gaji_pattern = re.compile(r'(ì œ\d+ì¡°ì˜\d+)[\s:.\)]*')
    hang_pattern = re.compile(r'(ì œ\d+í•­)[\s:.\)]*')
    ho_pattern = re.compile(r'(ì œ\d+í˜¸)[\s:.\)]*')

    result = {}
    # ê°€ì§€ì¡°ë¬¸ ë¶„ë¦¬ (ì œNì¡°ì˜M)
    gaji_splits = gaji_pattern.split(text)
    if len(gaji_splits) > 1:
        for i in range(1, len(gaji_splits), 2):
            gaji_title = gaji_splits[i]
            gaji_content = gaji_splits[i+1] if i+1 < len(gaji_splits) else ""
            result[gaji_title] = split_article_text_to_structure(gaji_content)
        return result

    # í•­ ë¶„ë¦¬
    hang_splits = hang_pattern.split(text)
    if len(hang_splits) > 1:
        hang_dict = {}
        preface = hang_splits[0]
        for i in range(1, len(hang_splits), 2):
            hang_title = hang_splits[i]
            hang_content = hang_splits[i+1] if i+1 < len(hang_splits) else ""
            # í˜¸ ë¶„ë¦¬
            ho_splits = ho_pattern.split(hang_content)
            if len(ho_splits) > 1:
                ho_dict = {}
                ho_preface = ho_splits[0]
                for j in range(1, len(ho_splits), 2):
                    ho_title = ho_splits[j]
                    ho_content = ho_splits[j+1] if j+1 < len(ho_splits) else ""
                    ho_dict[ho_title] = ho_content.strip()
                hang_dict[hang_title] = {'ë³¸ë¬¸': ho_preface.strip(), 'í˜¸': ho_dict}
            else:
                hang_dict[hang_title] = hang_content.strip()
        result = {'ë¨¸ë¦¿ë§': preface.strip(), 'í•­': hang_dict}
        return result

    return text.strip()

def get_law_id(law_name: str, api_key: str) -> Optional[str]:
    normalized = normalize_law_name(law_name)
    try:
        res = requests.get("https://www.law.go.kr/DRF/lawSearch.do", params={
            "OC": api_key,
            "target": "law",
            "type": "XML",
            "query": law_name,
            "pIndex": 1,
            "pSize": 10
        })
        res.raise_for_status()
        data = xmltodict.parse(res.text)
        law_root = data.get("LawSearch") or data.get("lawSearch") or {}
        laws = law_root.get("laws", {}).get("law") or law_root.get("law")
        if not laws:
            return None
        if isinstance(laws, dict):
            laws = [laws]
        for law in laws:
            name_fields = [law.get("ë²•ë ¹ëª…í•œê¸€", ""), law.get("ë²•ë ¹ì•½ì¹­ëª…", ""), law.get("ë²•ë ¹ëª…", "")]
            for name in name_fields:
                if normalize_law_name(name) == normalized:
                    return law.get("ë²•ë ¹ID")
        for law in laws:
            if law.get("í˜„í–‰ì—°í˜ì½”ë“œ") == "í˜„í–‰":
                return law.get("ë²•ë ¹ID")
        return None
    except Exception as e:
        print("[lawId ì˜¤ë¥˜]", e)
        return None

def fetch_article_html_fallback(law_name_full, article_no):
    try:
        law_url_name = quote(law_name_full.replace(' ', ''), safe='')
        article_path = quote(fix_article_no(article_no), safe='')
        article_url = f"https://www.law.go.kr/ë²•ë ¹/{law_url_name}/{article_path}"
        res = requests.get(article_url, timeout=7)
        res.raise_for_status()
        soup = BeautifulSoup(res.text, "html.parser")

        selectors = [
            ".law-article .article", ".article", ".law-article", "#article", ".cont_article",
            ".contlawview", "#conContents",
        ]
        main = None
        for sel in selectors:
            main = soup.select_one(sel)
            if main:
                break
        if main:
            text = main.get_text(separator="\n", strip=True)
            if "ì¡°ë¬¸ ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" not in text and len(text.strip()) > 20:
                return text, split_article_text_to_structure(text)

        text_blocks = []
        for tag in soup.find_all(['div', 'p', 'li', 'span', 'section']):
            t = tag.get_text(separator="\n", strip=True)
            if (
                len(t) > 20 and 
                re.search(r"(ì œ\s*\d+ì¡°|í•­|í˜¸|ê°€ì§€ì¡°ë¬¸|ë²•ë ¹|ëª©ì |ì‹œí–‰|ë²Œì¹™)", t)
            ):
                text_blocks.append(t)
        all_text = "\n".join(text_blocks)
        if all_text and len(all_text) > 20:
            return all_text, split_article_text_to_structure(all_text)

        return "HTMLì—ì„œ ì¡°ë¬¸ ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None
    except Exception as e:
        return f"(HTML fallback ì˜¤ë¥˜: {e})", None

def extract_article_with_full(xml_text, article_no_raw, clause_no=None, subclause_no=None, law_name_full=None):
    circled_nums = {'â‘ ': '1', 'â‘¡': '2', 'â‘¢': '3', 'â‘£': '4', 'â‘¤': '5', 'â‘¥': '6', 'â‘¦': '7', 'â‘§': '8', 'â‘¨': '9', 'â‘©': '10'}
    no, gaji, hang, ho, is_branch = parse_article_input(article_no_raw)
    canonical_article_no = None
    try:
        data = xmltodict.parse(xml_text)
        law = data.get("ë²•ë ¹", {})
        all_articles = []
        paths = [
            ["ì¡°ë¬¸", "ì¡°ë¬¸ë‹¨ìœ„"],
            ["ì¡°ë¬¸", "ì¡°ë¬¸ì¡°ë‹¨ìœ„"],
            ["ì¡°ë¬¸", "ê°€ì§€ì¡°ë¬¸ë‹¨ìœ„"],
            ["ì¡°ë¬¸", "ê°€ì§€ì¡°ë¬¸ì¡°ë‹¨ìœ„"],
            ["ì¡°ë¬¸", "ë³„í‘œë‹¨ìœ„"],
            ["ì¡°ë¬¸", "ë¶€ì¹™ë‹¨ìœ„"]
        ]
        for path in paths:
            cur = law
            try:
                for key in path:
                    cur = cur.get(key, {})
                if isinstance(cur, dict):
                    cur = [cur]
                if cur:
                    all_articles.extend(cur)
            except Exception:
                continue
        available = []
        matched_article = None
        for idx, article in enumerate(all_articles):
            no_raw = str(article.get("ì¡°ë¬¸ë²ˆí˜¸", "0"))
            this_article_name = no_raw
            is_gaji = "ì˜" in no_raw
            available.append(this_article_name)
            if normalize_article_no(this_article_name) == normalize_article_no(article_no_raw):
                matched_article = article
                canonical_article_no = this_article_name
                full_article = article.get("ì¡°ë¬¸ë‚´ìš©", "ë‚´ìš© ì—†ìŒ")
                if is_gaji:
                    if full_article and full_article != "ë‚´ìš© ì—†ìŒ":
                        return full_article, full_article, available, canonical_article_no, split_article_text_to_structure(full_article)
                    else:
                        ì•ˆë‚´ = (
                            f"í•´ë‹¹ ê°€ì§€ì¡°ë¬¸(ì¡°ë¬¸ë²ˆí˜¸: {this_article_name})ì€ ì‹œìŠ¤í…œì—ì„œ ìë™ ì¶”ì¶œì´ ë¶ˆê°€í•©ë‹ˆë‹¤.<br>"
                            f"ì•„ë˜ êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° ë°”ë¡œê°€ê¸°ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.<br>"
                            f"<a href='{make_article_link(law_name_full, article_no_raw)}'>êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° ë°”ë¡œê°€ê¸°</a>"
                        )
                        return ì•ˆë‚´, "", available, canonical_article_no, None
                if hang is None:
                    return full_article, full_article, available, canonical_article_no, split_article_text_to_structure(full_article)
                clauses = article.get("í•­", [])
                if isinstance(clauses, dict):
                    clauses = [clauses]
                for clause in clauses:
                    cnum = clause.get("í•­ë²ˆí˜¸", "").strip()
                    cnum_arabic = circled_nums.get(cnum, cnum)
                    if cnum_arabic == str(hang) or cnum == str(hang):
                        clause_content = clause.get("í•­ë‚´ìš©", "ë‚´ìš© ì—†ìŒ")
                        subclauses = clause.get("í˜¸", [])
                        if ho:
                            if isinstance(subclauses, dict):
                                subclauses = [subclauses]
                            for subclause in subclauses:
                                snum = subclause.get("í˜¸ë²ˆí˜¸", "").strip()
                                if snum == str(ho):
                                    return subclause.get("í˜¸ë‚´ìš©", "ë‚´ìš© ì—†ìŒ"), full_article, available, canonical_article_no, None
                            return "ìš”ì²­í•œ í˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", full_article, available, canonical_article_no, None
                        return clause_content, full_article, available, canonical_article_no, None
                return "ìš”ì²­í•œ í•­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", full_article, available, canonical_article_no, None
        # Fallback: ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨, HTMLì—ì„œ êµ¬ì¡°ë¶„ë¦¬
        if law_name_full and article_no_raw:
            html_text, structured_json = fetch_article_html_fallback(law_name_full, article_no_raw)
            ì•ˆë‚´ = (
                f"API/DBì— ì¡°ë¬¸ ë³¸ë¬¸ì´ ì—†ì–´ ì›¹í˜ì´ì§€ì—ì„œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.<br>"
                f"ì•„ë˜ êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° ë°”ë¡œê°€ê¸°ë„ ì°¸ê³ í•˜ì„¸ìš”.<br>"
                f"<a href='{make_article_link(law_name_full, article_no_raw)}'>êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° ë°”ë¡œê°€ê¸°</a><br>"
                f"<br>ë³¸ë¬¸:<br>{html_text if html_text else 'ì›¹í˜ì´ì§€ì—ì„œë„ ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨'}"
            )
            return (
                ì•ˆë‚´,
                html_text if html_text else "",
                available,
                canonical_article_no,
                structured_json
            )
        ì•ˆë‚´ = (
            f"ìš”ì²­í•œ ì¡°ë¬¸({article_no_raw})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.<br>"
            f"ì‹¤ì œ ì¡°íšŒ ê°€ëŠ¥í•œ ì¡°ë¬¸ë²ˆí˜¸: {', '.join(available) if available else 'ì—†ìŒ'}<br>"
            f"ì•„ë˜ êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°ì—ì„œ ì§ì ‘ í™•ì¸í•˜ì„¸ìš”.<br>"
            f"<a href='{make_article_link(law_name_full, None)}'>ë²•ë ¹ ë°”ë¡œê°€ê¸°</a>"
        )
        return ì•ˆë‚´, "", available, None, None
    except Exception as e:
        return f"íŒŒì‹± ì˜¤ë¥˜: {e}", "", [], None, None

def make_markdown_table(law_name, article_no, clause_no, subclause_no, ë‚´ìš©, ë²•ë ¹ë§í¬, ì¡°ë¬¸ì „ì²´, available_articles=None):
    ë‚´ìš©_fmt = ë‚´ìš©.replace("|", "\\|").replace("\n", "<br>")
    ì¡°ë¬¸ì „ì²´_fmt = ì¡°ë¬¸ì „ì²´.replace("|", "\\|").replace("\n", "<br>")
    tbl = (
        "| í•­ëª© | ë‚´ìš© |\n"
        "|------|------|\n"
        f"| ë²•ë ¹ëª… | {law_name} |\n"
        f"| ì¡°ë¬¸ | {article_no or ''} |\n"
        f"| í•­ | {str(clause_no)+'í•­' if clause_no else ''} |\n"
        f"| í˜¸ | {str(subclause_no)+'í˜¸' if subclause_no else ''} |\n"
        f"| ë‚´ìš© | {ë‚´ìš©_fmt} |\n"
        f"| ì¡°ë¬¸ ì „ì²´ | {ì¡°ë¬¸ì „ì²´_fmt} |\n"
        f"| ì¶œì²˜ | [êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° ë°”ë¡œê°€ê¸°]({ë²•ë ¹ë§í¬}) |\n"
    )
    if available_articles:
        tbl += f"| ì¡°íšŒê°€ëŠ¥ ì¡°ë¬¸ë²ˆí˜¸ | {', '.join(available_articles)} |\n"
    return tbl

@app.get("/")
@app.head("/")
def root():
    return add_privacy_notice({"message": "School LawBot API is running."})

@app.get("/healthz")
@app.head("/healthz")
def health_check():
    return add_privacy_notice({"status": "ok"})

@app.get("/ping")
@app.head("/ping")
def ping():
    return add_privacy_notice({"status": "ok"})

@app.get("/privacy-policy")
def privacy_policy():
    return add_privacy_notice({
        "message": "ë³¸ ì„œë¹„ìŠ¤ì˜ ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ì€ ë‹¤ìŒ ë§í¬ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "url": PRIVACY_URL
    })

@app.get("/law", summary="ë²•ë ¹ ì¡°ë¬¸ ì¡°íšŒ")
@app.head("/law")
def get_law_clause(
    law_name: str = Query(None, example="í•™êµí­ë ¥ì˜ˆë°©ë²•ì‹œí–‰ë ¹"),
    article_no: str = Query(None, example="ì œ14ì¡°ì˜ 2"),
    clause_no: Optional[str] = Query(None),
    subclause_no: Optional[str] = Query(None),
    request: Request = None
):
    if not law_name or not article_no:
        return add_privacy_notice({
            "error": "law_name, article_no íŒŒë¼ë¯¸í„°ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤. ì˜ˆì‹œ: /law?law_name=í•™êµí­ë ¥ì˜ˆë°©ë²•ì‹œí–‰ë ¹&article_no=ì œ14ì¡°ì˜ 2"
        })
    api_key = API_KEY
    log_entry = {
        "timestamp": datetime.datetime.now().isoformat(),
        "client_ip": request.client.host if request else "unknown",
        "law_name": law_name,
        "article_no": article_no,
        "clause_no": clause_no,
        "subclause_no": subclause_no,
        "api_key": api_key
    }
    try:
        law_name_full = resolve_full_law_name(law_name)
        law_id = get_law_id(law_name_full, api_key)
        if not law_id:
            log_entry["status"] = "error"
            log_entry["error"] = "ë²•ë ¹ ID ì¡°íšŒ ì‹¤íŒ¨"
            recent_logs.append(log_entry)
            if len(recent_logs) > 50:
                recent_logs.pop(0)
            return JSONResponse(content=add_privacy_notice({
                "error": "ë²•ë ¹ ID ì¡°íšŒ ì‹¤íŒ¨",
                "ì•ˆë‚´": "ì…ë ¥í•œ ë²•ë ¹ëª…ì´ ì •í™•í•œì§€ í™•ì¸í•˜ê±°ë‚˜, ì•„ë˜ êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°ì—ì„œ ì§ì ‘ ê²€ìƒ‰í•´ ì£¼ì„¸ìš”.",
                "ë²•ë ¹ë©”ì¸": make_article_link(law_name_full, None)
            }), status_code=404)
        res = requests.get("https://www.law.go.kr/DRF/lawService.do", params={
            "OC": api_key,
            "target": "law",
            "type": "XML",
            "ID": law_id,
            "pIndex": 1,
            "pSize": 1000
        })
        res.raise_for_status()
        if "ë²•ë ¹ì´ ì—†ìŠµë‹ˆë‹¤" in res.text:
            log_entry["status"] = "error"
            log_entry["error"] = "í•´ë‹¹ ë²•ë ¹ì€ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            recent_logs.append(log_entry)
            if len(recent_logs) > 50:
                recent_logs.pop(0)
            return JSONResponse(content=add_privacy_notice({
                "error": "í•´ë‹¹ ë²•ë ¹ì€ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "ë²•ë ¹ë©”ì¸": make_article_link(law_name_full, None)
            }), status_code=403)
        article_no_norm = normalize_article_no(article_no)
        ë‚´ìš©, ì¡°ë¬¸ì „ì²´, available_articles, canonical_article_no, êµ¬ì¡°í™” = extract_article_with_full(
            res.text, article_no_norm, clause_no, subclause_no, law_name_full
        )
        law_url = make_article_link(law_name_full, canonical_article_no or article_no_norm)
        markdown = make_markdown_table(
            law_name_full, canonical_article_no or article_no_norm,
            clause_no, subclause_no, ë‚´ìš©, law_url, ì¡°ë¬¸ì „ì²´, available_articles
        )
        result = {
            "source": "api",
            "ì¶œì²˜": "lawService+HTMLfallback+êµ¬ì¡°í™”",
            "ë²•ë ¹ëª…": law_name_full,
            "ì¡°ë¬¸": f"{canonical_article_no or article_no_norm}" if article_no else "",
            "í•­": f"{clause_no}í•­" if clause_no else "",
            "í˜¸": f"{subclause_no}í˜¸" if subclause_no else "",
            "ë‚´ìš©": ë‚´ìš©,
            "ì¡°ë¬¸ì „ì²´": ì¡°ë¬¸ì „ì²´,
            "êµ¬ì¡°í™”": êµ¬ì¡°í™”,  # í•­/í˜¸/ê°€ì§€ì¡°ë¬¸ ìë™ ë¶„ë¦¬ êµ¬ì¡°
            "ë²•ë ¹ë§í¬": law_url,
            "markdown": markdown,
            "ì¡°ë¬¸ëª©ë¡": available_articles
        }
        log_entry["status"] = "success"
        log_entry["result"] = result
        recent_logs.append(log_entry)
        if len(recent_logs) > 50:
            recent_logs.pop(0)
        return JSONResponse(content=add_privacy_notice(result))
    except Exception as e:
        log_entry["status"] = "error"
        log_entry["error"] = str(e)
        recent_logs.append(log_entry)
        if len(recent_logs) > 50:
            recent_logs.pop(0)
        print("ğŸš¨ API ì—ëŸ¬:", e)
        return JSONResponse(content=add_privacy_notice({
            "error": "API í˜¸ì¶œ ì‹¤íŒ¨",
            "ì—ëŸ¬ë‚´ìš©": str(e)
        }), status_code=500)

@app.get("/test-log", summary="ìµœê·¼ ìš”ì²­ ë¡œê·¸ 10ê±´ ì¡°íšŒ")
@app.head("/test-log")
def test_log():
    return add_privacy_notice({"recent_logs": recent_logs[-10:]})
# === [ì¶”ê°€ 1] ë²•ë ¹ëª©ë¡ì¡°íšŒì„œë¹„ìŠ¤ (LawListService) ===
@app.get("/law-list", summary="ë²•ë ¹ëª©ë¡ì¡°íšŒì„œë¹„ìŠ¤(LawListService)")
def get_law_list(
    query: Optional[str] = Query(None, example="í•™êµí­ë ¥"),
    law_cls: Optional[str] = Query(None, description="ë²•ë ¹êµ¬ë¶„ì½”ë“œ(ì˜ˆ: 001)", example="001"),
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100),
):
    params = {
        "OC": API_KEY,
        "target": "law",
        "type": "XML",
        "pIndex": page,
        "pSize": page_size,
    }
    if query:
        params["query"] = query
    if law_cls:
        params["displayCls"] = law_cls
    res = requests.get("https://www.law.go.kr/DRF/lawSearch.do", params=params)
    res.raise_for_status()
    data = xmltodict.parse(res.text)
    return add_privacy_notice(data)

# === [ì¶”ê°€ 2] ì¡°ë¬¸ëª©ë¡ì¡°íšŒì„œë¹„ìŠ¤ (ArticleListService) ===
@app.get("/article-list", summary="ì¡°ë¬¸ëª©ë¡ì¡°íšŒì„œë¹„ìŠ¤(ArticleListService)")
def get_article_list(
    law_id: str = Query(..., example="52413"),
    type: str = Query("XML", description="XML ë˜ëŠ” JSON"),
):
    params = {
        "OC": API_KEY,
        "target": "article",
        "type": type.upper(),
        "ID": law_id,
        "pIndex": 1,
        "pSize": 1000
    }
    res = requests.get("https://www.law.go.kr/DRF/articleList.do", params=params)
    res.raise_for_status()
    if type.upper() == "JSON":
        return add_privacy_notice(res.json())
    else:
        return add_privacy_notice(xmltodict.parse(res.text))

# === [ì¶”ê°€ 3] ì¡°ë¬¸ìƒì„¸ì¡°íšŒì„œë¹„ìŠ¤ (ArticleService) ===
@app.get("/article-detail", summary="ì¡°ë¬¸ìƒì„¸ì¡°íšŒì„œë¹„ìŠ¤(ArticleService)")
def get_article_detail(
    law_id: str = Query(..., example="52413"),
    article_seq: str = Query(..., example="1084544"),
    type: str = Query("XML", description="XML ë˜ëŠ” JSON"),
):
    params = {
        "OC": API_KEY,
        "target": "article",
        "type": type.upper(),
        "ID": law_id,
        "articleSeq": article_seq
    }
    res = requests.get("https://www.law.go.kr/DRF/articleService.do", params=params)
    res.raise_for_status()
    if type.upper() == "JSON":
        return add_privacy_notice(res.json())
    else:
        return add_privacy_notice(xmltodict.parse(res.text))

# === [ì¶”ê°€ 4] í†µí•© ìŠ¤í‚¤ë§ˆ ì•ˆë‚´ (ì˜ˆì‹œ) ===
openapi_schemas = {
    "law-list": {
        "ë²•ë ¹ëª©ë¡": [
            {
                "ë²•ë ¹ID": "52413",
                "ë²•ë ¹ëª…í•œê¸€": "í•™êµí­ë ¥ì˜ˆë°© ë° ëŒ€ì±…ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ë ¹",
                "ë²•ë ¹ì•½ì¹­ëª…": "...",
                "ê³µí¬ì¼ì": "YYYYMMDD",
                "ì‹œí–‰ì¼ì": "YYYYMMDD",
                # ... ê¸°íƒ€ í•„ë“œ
            }
        ]
    },
    "article-list": {
        "ì¡°ë¬¸ëª©ë¡": [
            {
                "ì¡°ë¬¸ID": "1084544",
                "ì¡°ë¬¸ë²ˆí˜¸": "ì œ14ì¡°ì˜3",
                "ì¡°ë¬¸ì œëª©": "...",
                "ì¡°ë¬¸êµ¬ë¶„": "...",
                # ... ê¸°íƒ€
            }
        ]
    },
    "article-detail": {
        "ì¡°ë¬¸ìƒì„¸": {
            "ì¡°ë¬¸ID": "1084544",
            "ì¡°ë¬¸ë²ˆí˜¸": "ì œ14ì¡°ì˜3",
            "ì¡°ë¬¸ì œëª©": "...",
            "ì¡°ë¬¸ë‚´ìš©": "...",
            # ... ê¸°íƒ€
        }
    }
}

@app.get("/schema", summary="í†µí•© ìŠ¤í‚¤ë§ˆ/ì˜ˆì‹œ")
def get_openapi_schema():
    """
    í†µí•© ì„œë¹„ìŠ¤ ìŠ¤í‚¤ë§ˆ(ì˜ˆì‹œ) ì•ˆë‚´
    """
    return add_privacy_notice(openapi_schemas)
